{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3 - Model\n",
    "\n",
    "In this tutorial a very simple PyTorch CNN model is prepared that should help classify information in the images we have reviewed we are working with in the `Tutorial 2`. Specific details will not be over explained in what is done, as this will turn into a seperate Deep Learning type tutorial, but attempt at commenting the most crucial parts of the model and what is done are done.\n",
    "\n",
    "If you have zero understanding of working with PyTorch, then my recommendations is just to stick arround to understand how the deployment concept will be delivered. While if you are interested in learning more, I do heavily recommend visiting the following links (I manged to learn PyTorch with them quite quickly and do my MSc):\n",
    "\n",
    "* https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials\n",
    "* https://deeplizard.com/learn/playlist/PLZbbT5o_s2xrfNyHZsM6ufI0iZENK9xgG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us load the main packages and their components\n",
    "import torch                                 # For PyTorch\n",
    "import torch.nn as nn                        # Neural Network components of PyTorch\n",
    "import torch.nn.functional as F              # PyTorches functionability of various Deep Learning components\n",
    "import torch.optim as optim                  # Optimization functionability of PyTorch during the training process\n",
    "from torchvision import datasets, transforms # Datasets and gradual loading class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following device is used: cpu\n"
     ]
    }
   ],
   "source": [
    "# First I will switch the processing power of PyTorch from cpu to gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu') # But we will chose cpu eitherway for deployment reasons\n",
    "# PyTorch models need to be saved and ran on the same systems\n",
    "# If you do not have cuda or a GPU, you will still work with CPU further, it should not be an issue\n",
    "print(\"The following device is used: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to prepare the training and testing datasets. As this is a new project, they have to be re-downloaded.\n",
    "# Alternativelly, you can locate where your earlier downloaded training data was stored and re-use it.\n",
    "\n",
    "# Loading the training set\n",
    "mnist_training = datasets.MNIST(root = \"./data\",                    # Location where the data will be saved\n",
    "                                train = True,                       # It is a training set\n",
    "                                transform = transforms.ToTensor(),  # We will transform the data to actual torch Tensors\n",
    "                                download = True)                    # We want to download it again\n",
    "\n",
    "\n",
    "# Loading the testing set\n",
    "mnist_testing = datasets.MNIST(root = \"./data\",                     # The data is not redownloaded but taken from existing\n",
    "                               train = False,                       # This is not a training data, so false\n",
    "                               transform = transforms.ToTensor())   # Data is converted to torch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,\n",
      "          18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
      "         253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253,\n",
      "         253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253,\n",
      "         198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,\n",
      "          11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,\n",
      "           2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,\n",
      "          70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241,\n",
      "         225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81,\n",
      "         240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
      "         229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253,\n",
      "         253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253,\n",
      "         253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,\n",
      "          80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
      "       dtype=torch.uint8)\n",
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "# Now just take a quick glance what changed about the data, as it was transformed into tensors\n",
    "print(mnist_training.data[0])\n",
    "print(mnist_training.targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see - not much changed. But this format will make our lifes easier in working with PyTorch. In reality it would also be great to re-scale the pixel values into the range from 0 to 1, with all the values being in the middle, however, for such a simple example this step is omitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set is 60000 datapoints long\n",
      "The testing set is 10000 datapoints long\n"
     ]
    }
   ],
   "source": [
    "# Sizes of our samples:\n",
    "print(\"The training set is {} datapoints long\\nThe testing set is {} datapoints long\".format(len(mnist_training), len(mnist_testing)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now prepare the dataloader that will be feeding infromation to the model. This should save on the processing memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chose a batch size the files will be loaded to the network to be worked with\n",
    "BATCH = 16\n",
    "\n",
    "# Loader for the training data\n",
    "train_loader = torch.utils.data.DataLoader(dataset = mnist_training,  #Specify our training data\n",
    "                                           batch_size = BATCH,        #Specify the Batch size\n",
    "                                           shuffle = True)            #Shufle data for more efficient training\n",
    "\n",
    "# Loader for the testing data\n",
    "test_loader = torch.utils.data.DataLoader(dataset = mnist_testing,    #Specify our testing data\n",
    "                                          batch_size = BATCH,         #Specify the Batch size\n",
    "                                          shuffle = False)            #No point in allowing for constant shuffling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have everything prepared for working with the data feeding process - we can create a model that will be working with predicting the data. It willl be a simple 3 layer convolutional network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a network\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):                                             # Make few inits in the beginning\n",
    "        super(Network, self).__init__()                             # Extend the Network class\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 1,\n",
    "                      out_channels = 16,\n",
    "                      kernel_size = 5,\n",
    "                      stride = 1,\n",
    "                      padding = 2),                                     # First convolutional layer\n",
    "            nn.ReLU(),                                                  # ReLU activation applied\n",
    "            nn.MaxPool2d(kernel_size=2, \n",
    "                         stride=2)                                      # Pooling applied\n",
    "            )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 16,\n",
    "                      out_channels = 32,\n",
    "                      kernel_size = 5,\n",
    "                      stride = 1,\n",
    "                      padding = 2),                                     # Second convolutional layer\n",
    "            nn.ReLU(),                                                  # ReLU activation applied\n",
    "            nn.MaxPool2d(kernel_size = 2,\n",
    "                         stride = 2)                                    # Pooling applied \n",
    "            )\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features = 7*7*32,                  # For more information on calculations: https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_convolutional_neuralnetwork/\n",
    "                             out_features = 10)                     # A fully connected output layer (Dense layer)\n",
    "    \n",
    "    # A method for putting information through the network\n",
    "    # t - is a tensor of information essentially\n",
    "    def forward(self, t):\n",
    "        out = self.conv1(t)\n",
    "        out = self.conv2(out)\n",
    "        out = out.reshape(out.size(0), -1) # Small reshaping of information is required before going to the Dense Layer\n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructor for the network has been made. Now it is time to initiate a network-object, but also few parameters will have to be passed to it. Such as an optimizer for training. A learning rate and similare. Let's do all of that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some hyperparameters\n",
    "EPOCHS = 10                       # Amount of Epochs to traing the network for            \n",
    "LEARNING_RATE = 0.001             # The learning rate of the optimizer network will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create a network object\n",
    "model = Network().to(device)\n",
    "# The model is stored on a device, so the gpu could work with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=1568, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if it saved\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now set few conditions on how the network will process data through it\n",
    "CRITERION = nn.CrossEntropyLoss()                 # Criteria for classification the network will work with\n",
    "OPTIMIZER = torch.optim.Adam(model.parameters(),  # Optimizer the network will use\n",
    "                             lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [500/3750], Loss: 0.1854\n",
      "Epoch [1/10], Step [1000/3750], Loss: 0.0292\n",
      "Epoch [1/10], Step [1500/3750], Loss: 0.2691\n",
      "Epoch [1/10], Step [2000/3750], Loss: 0.0983\n",
      "Epoch [1/10], Step [2500/3750], Loss: 0.0022\n",
      "Epoch [1/10], Step [3000/3750], Loss: 0.1077\n",
      "Epoch [1/10], Step [3500/3750], Loss: 0.1953\n",
      "Total Loss per Epoch: 465.56\n",
      "\n",
      "Epoch [2/10], Step [500/3750], Loss: 0.0047\n",
      "Epoch [2/10], Step [1000/3750], Loss: 0.0017\n",
      "Epoch [2/10], Step [1500/3750], Loss: 0.0619\n",
      "Epoch [2/10], Step [2000/3750], Loss: 0.0975\n",
      "Epoch [2/10], Step [2500/3750], Loss: 0.0103\n",
      "Epoch [2/10], Step [3000/3750], Loss: 0.0275\n",
      "Epoch [2/10], Step [3500/3750], Loss: 0.0001\n",
      "Total Loss per Epoch: 173.17\n",
      "\n",
      "Epoch [3/10], Step [500/3750], Loss: 0.0048\n",
      "Epoch [3/10], Step [1000/3750], Loss: 0.0027\n",
      "Epoch [3/10], Step [1500/3750], Loss: 0.0093\n",
      "Epoch [3/10], Step [2000/3750], Loss: 0.0595\n",
      "Epoch [3/10], Step [2500/3750], Loss: 0.0088\n",
      "Epoch [3/10], Step [3000/3750], Loss: 0.0248\n",
      "Epoch [3/10], Step [3500/3750], Loss: 0.0007\n",
      "Total Loss per Epoch: 115.33\n",
      "\n",
      "Epoch [4/10], Step [500/3750], Loss: 0.0166\n",
      "Epoch [4/10], Step [1000/3750], Loss: 0.0005\n",
      "Epoch [4/10], Step [1500/3750], Loss: 0.0033\n",
      "Epoch [4/10], Step [2000/3750], Loss: 0.0016\n",
      "Epoch [4/10], Step [2500/3750], Loss: 0.0001\n",
      "Epoch [4/10], Step [3000/3750], Loss: 0.0006\n",
      "Epoch [4/10], Step [3500/3750], Loss: 0.0001\n",
      "Total Loss per Epoch: 89.24\n",
      "\n",
      "Epoch [5/10], Step [500/3750], Loss: 0.0006\n",
      "Epoch [5/10], Step [1000/3750], Loss: 0.0001\n",
      "Epoch [5/10], Step [1500/3750], Loss: 0.0003\n",
      "Epoch [5/10], Step [2000/3750], Loss: 0.0015\n",
      "Epoch [5/10], Step [2500/3750], Loss: 0.0006\n",
      "Epoch [5/10], Step [3000/3750], Loss: 0.0008\n",
      "Epoch [5/10], Step [3500/3750], Loss: 0.0011\n",
      "Total Loss per Epoch: 70.19\n",
      "\n",
      "Epoch [6/10], Step [500/3750], Loss: 0.0298\n",
      "Epoch [6/10], Step [1000/3750], Loss: 0.0002\n",
      "Epoch [6/10], Step [1500/3750], Loss: 0.0011\n",
      "Epoch [6/10], Step [2000/3750], Loss: 0.0085\n",
      "Epoch [6/10], Step [2500/3750], Loss: 0.0122\n",
      "Epoch [6/10], Step [3000/3750], Loss: 0.0653\n",
      "Epoch [6/10], Step [3500/3750], Loss: 0.0002\n",
      "Total Loss per Epoch: 55.69\n",
      "\n",
      "Epoch [7/10], Step [500/3750], Loss: 0.0001\n",
      "Epoch [7/10], Step [1000/3750], Loss: 0.0235\n",
      "Epoch [7/10], Step [1500/3750], Loss: 0.0167\n",
      "Epoch [7/10], Step [2000/3750], Loss: 0.0002\n",
      "Epoch [7/10], Step [2500/3750], Loss: 0.0594\n",
      "Epoch [7/10], Step [3000/3750], Loss: 0.0372\n",
      "Epoch [7/10], Step [3500/3750], Loss: 0.0017\n",
      "Total Loss per Epoch: 44.89\n",
      "\n",
      "Epoch [8/10], Step [500/3750], Loss: 0.0005\n",
      "Epoch [8/10], Step [1000/3750], Loss: 0.0083\n",
      "Epoch [8/10], Step [1500/3750], Loss: 0.0001\n",
      "Epoch [8/10], Step [2000/3750], Loss: 0.0000\n",
      "Epoch [8/10], Step [2500/3750], Loss: 0.3459\n",
      "Epoch [8/10], Step [3000/3750], Loss: 0.0151\n",
      "Epoch [8/10], Step [3500/3750], Loss: 0.0000\n",
      "Total Loss per Epoch: 39.2\n",
      "\n",
      "Epoch [9/10], Step [500/3750], Loss: 0.0007\n",
      "Epoch [9/10], Step [1000/3750], Loss: 0.0014\n",
      "Epoch [9/10], Step [1500/3750], Loss: 0.0000\n",
      "Epoch [9/10], Step [2000/3750], Loss: 0.0001\n",
      "Epoch [9/10], Step [2500/3750], Loss: 0.0001\n",
      "Epoch [9/10], Step [3000/3750], Loss: 0.0000\n",
      "Epoch [9/10], Step [3500/3750], Loss: 0.0012\n",
      "Total Loss per Epoch: 33.41\n",
      "\n",
      "Epoch [10/10], Step [500/3750], Loss: 0.0001\n",
      "Epoch [10/10], Step [1000/3750], Loss: 0.0000\n",
      "Epoch [10/10], Step [1500/3750], Loss: 0.0022\n",
      "Epoch [10/10], Step [2000/3750], Loss: 0.0002\n",
      "Epoch [10/10], Step [2500/3750], Loss: 0.0000\n",
      "Epoch [10/10], Step [3000/3750], Loss: 0.0000\n",
      "Epoch [10/10], Step [3500/3750], Loss: 0.0000\n",
      "Total Loss per Epoch: 26.72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now prepare the training loop for the network. They are often similar in how they are structured\n",
    "\n",
    "# Put the network first in the training mode\n",
    "model.train()\n",
    "\n",
    "# Set conditions for the network to train\n",
    "# For how many steps will the network train\n",
    "total_step = len(train_loader)\n",
    "\n",
    "# Initiate training per epochs\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    for i, (images, labels) in enumerate(train_loader): # images - data // labels - targets (classes)\n",
    "        images = images.to(device) #Put the values on the device for PyTorch to process (here it is a GPU)\n",
    "        labels = labels.to(device) #Put the values on the device for PyTorch to process (here it is a GPU)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)            # Let the network pass the information through it\n",
    "        loss = CRITERION(outputs, labels)  # Calculate the loss of predictions the network makes\n",
    "        epoch_loss += loss                 # Calculate epoch loss\n",
    "        \n",
    "        # Backward and optimize\n",
    "        OPTIMIZER.zero_grad()\n",
    "        loss.backward()         # Backpropogate the information\n",
    "        OPTIMIZER.step()      \n",
    "        \n",
    "        # Give a bit of a visual que on what is going on with the network to the one who trains it\n",
    "        if (i + 1) % 500 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, EPOCHS, i + 1, total_step, loss.item()))\n",
    "        if (i + 1 == total_step):\n",
    "            print(\"Total Loss per Epoch: {}\\n\".format(round(epoch_loss.item(), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen - loss has been dereasing over time. Now we can test the accuracy of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 99.05 %\n"
     ]
    }
   ],
   "source": [
    "# Put the model into the evaluation mode\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad(): # Turn off the gradient accumulator\n",
    "    correct = 0       # Correct predictions\n",
    "    total = 0         # Total predictions\n",
    "    \n",
    "    # Now go through the testing set\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)      # images - data // labels - targets (classes)\n",
    "        labels = labels.to(device)      # Put everything to a device\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a model with a 99.05% accuracy rate. Seems quite good. Now time to save it and move on to making it deployable to the real world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.0.weight',\n",
       "              tensor([[[[ 1.1127e-01, -2.8221e-01, -4.1433e-01, -3.0182e-01,  1.2833e-01],\n",
       "                        [-6.2853e-01, -4.6515e-01, -1.8315e-01, -2.7313e-02,  3.4319e-01],\n",
       "                        [-3.3926e-01, -2.1037e-01, -1.3936e-01,  1.7931e-01,  1.0549e-01],\n",
       "                        [-4.2705e-01, -1.3187e-01,  1.5330e-02,  3.8126e-01,  1.7717e-01],\n",
       "                        [ 1.9778e-01,  2.3199e-02,  2.3313e-01,  1.2574e-01,  2.0287e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.5177e-01,  3.9931e-02,  1.7255e-01, -2.3502e-01, -9.1032e-02],\n",
       "                        [-8.6563e-02,  8.0684e-02,  1.9807e-01, -7.1137e-02, -7.4522e-01],\n",
       "                        [ 6.0676e-02, -4.1934e-01,  1.0396e-01,  1.2970e-01, -2.4970e-01],\n",
       "                        [-1.4771e-01, -2.8255e-01, -9.8548e-02,  2.6374e-01,  4.1852e-01],\n",
       "                        [ 2.6158e-01,  3.3006e-01,  1.0052e-02, -1.5940e-01,  9.1756e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.3794e-01, -9.4181e-01, -5.0006e-01, -4.7973e-01, -2.2100e-01],\n",
       "                        [-5.1381e-02, -1.6586e-01, -2.0522e-01, -4.4058e-01, -5.6816e-01],\n",
       "                        [ 3.9688e-01,  1.1025e-01, -1.5472e-02,  2.5629e-02,  1.4613e-02],\n",
       "                        [-8.5323e-04,  1.6364e-01,  4.7017e-02,  8.5065e-02,  1.6700e-01],\n",
       "                        [ 6.4706e-02,  5.2285e-02,  3.2407e-01,  2.0785e-01,  2.8346e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.7035e-01,  2.0828e-01,  2.6998e-02,  3.4125e-01,  1.4583e-01],\n",
       "                        [ 3.0990e-02,  3.0800e-01,  2.2925e-01,  8.1814e-02,  5.5631e-02],\n",
       "                        [ 3.3784e-01,  1.1255e-01, -7.8163e-02, -1.9701e-01, -7.5529e-02],\n",
       "                        [ 2.2961e-01,  7.2596e-02, -3.6796e-01, -2.3014e-01, -3.5908e-01],\n",
       "                        [ 4.2826e-05, -4.7435e-01, -3.1427e-01, -2.3582e-01,  1.2208e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.3288e-01,  2.0154e-01,  3.3619e-01,  7.6273e-02,  9.6737e-02],\n",
       "                        [-5.5503e-02, -6.1973e-02, -2.4185e-01,  1.0023e-01,  9.3843e-02],\n",
       "                        [-3.4500e-01, -4.2687e-01, -2.6403e-01,  3.1081e-01,  2.0085e-01],\n",
       "                        [-4.6762e-01, -4.0148e-02,  2.7325e-01,  4.1461e-02,  1.9229e-01],\n",
       "                        [ 1.4205e-01,  3.5523e-02,  1.4219e-01, -2.4356e-01,  4.6991e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.2367e-02,  1.7130e-01, -2.4000e-01, -1.6975e-01,  1.4172e-01],\n",
       "                        [ 1.2109e-01,  1.5276e-01, -1.8765e-01, -3.0275e-01,  1.8341e-01],\n",
       "                        [ 2.0683e-01,  5.1446e-02,  1.1214e-02, -3.2225e-01, -2.5362e-01],\n",
       "                        [ 1.6226e-01,  2.5304e-01, -1.0699e-02,  3.2475e-02, -2.8270e-01],\n",
       "                        [ 2.7292e-02,  2.5066e-01,  9.9857e-02,  9.2270e-02, -1.4669e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.5286e-01, -1.3391e-01, -2.6077e-01, -3.3750e-01, -7.3537e-02],\n",
       "                        [-1.5528e-01, -4.7987e-01, -2.0456e-01, -3.9309e-02,  1.2704e-01],\n",
       "                        [-3.1421e-02, -4.2889e-01,  2.3168e-01,  3.0320e-01, -1.2863e-01],\n",
       "                        [-3.7587e-01, -5.0241e-02,  1.2000e-01,  5.4859e-02, -8.2786e-02],\n",
       "                        [-4.3621e-01, -1.3206e-01, -1.2024e-01,  3.9818e-02, -5.3504e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.0932e-01, -3.7495e-01, -3.0291e-01, -2.4232e-02,  2.5076e-01],\n",
       "                        [ 3.1630e-01, -4.2705e-01, -7.8942e-01,  1.5667e-01,  3.3858e-01],\n",
       "                        [ 1.4760e-01, -4.3883e-01, -7.2615e-01,  2.2327e-01,  1.9437e-01],\n",
       "                        [ 2.3107e-01, -8.8729e-01, -5.2230e-01,  1.1610e-01,  1.8043e-01],\n",
       "                        [-4.1699e-02, -2.2754e-01, -5.2869e-01,  6.3633e-02,  1.0351e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1824e-01,  6.3353e-02, -2.0904e-02, -2.8556e-01, -4.1734e-01],\n",
       "                        [-1.0138e-01,  1.2089e-01,  3.3608e-01, -2.7638e-01, -7.4481e-01],\n",
       "                        [ 8.6781e-02,  8.3990e-02,  5.7326e-01,  4.9129e-01, -1.3258e-01],\n",
       "                        [-8.1688e-03, -5.5866e-02,  6.7192e-02,  2.0880e-01,  1.9636e-01],\n",
       "                        [-1.9465e-01, -8.4752e-02, -1.2000e-01, -1.1702e-01,  9.6903e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4600e-01, -6.2207e-02,  3.2621e-02, -2.6113e-01, -4.7516e-01],\n",
       "                        [-2.3095e-01,  1.4220e-01,  2.8669e-01,  8.9314e-02, -4.7440e-01],\n",
       "                        [ 1.4364e-01,  1.4064e-01,  4.2716e-01,  5.6626e-01, -1.2998e-01],\n",
       "                        [-3.8548e-01, -4.1205e-01, -2.4644e-01,  3.2724e-01,  7.3926e-03],\n",
       "                        [-2.0645e-01, -3.6093e-01, -3.2692e-01, -1.5268e-01,  1.7270e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.7923e-02,  2.5793e-01, -1.3587e-01, -1.9897e-03,  1.9090e-01],\n",
       "                        [-2.4725e-01,  2.0346e-01,  1.4919e-01, -2.0427e-01, -1.2290e-01],\n",
       "                        [-1.9482e-01,  3.8416e-01,  2.7059e-01, -2.4136e-01, -3.5804e-01],\n",
       "                        [-2.4990e-02,  2.7540e-01, -1.8254e-02, -9.0622e-02, -1.3711e-01],\n",
       "                        [-1.4815e-01,  1.9362e-01, -3.8620e-03, -1.4954e-01, -2.0733e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.0412e-01,  5.4041e-02, -2.9874e-01, -5.4476e-01, -1.9217e-01],\n",
       "                        [-1.2858e-01,  1.5154e-01, -3.7461e-01, -1.0567e-01,  3.2417e-01],\n",
       "                        [-4.0121e-02, -5.3860e-02,  3.6916e-02,  4.1853e-01,  3.6882e-01],\n",
       "                        [ 6.8721e-02,  3.3386e-01,  3.3559e-01, -8.3612e-02, -3.2022e-01],\n",
       "                        [ 3.9657e-02,  1.1085e-01, -3.0037e-01, -1.3510e-01, -3.4290e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4583e-02, -2.7637e-01, -1.6782e-01,  1.8242e-01,  1.3974e-01],\n",
       "                        [-4.7878e-01, -1.7021e-01,  3.1825e-01,  4.2232e-01, -6.4582e-02],\n",
       "                        [ 3.9626e-02, -1.4848e-02,  1.5916e-02,  9.5480e-02, -1.2485e-01],\n",
       "                        [-1.2840e-01, -1.1044e-01,  3.0722e-01,  7.6959e-02, -3.1776e-01],\n",
       "                        [ 3.1047e-03, -1.6489e-01, -1.1757e-01, -1.8487e-01, -2.1754e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.8963e-01,  4.1490e-01,  2.2212e-01, -4.2102e-03,  1.9362e-01],\n",
       "                        [ 1.5108e-02,  4.0568e-01,  3.7483e-01,  3.6662e-02, -3.1745e-02],\n",
       "                        [-3.3724e-01, -1.3556e-01,  2.2265e-01,  2.9868e-02, -1.9803e-01],\n",
       "                        [-6.1199e-01, -6.0475e-01, -2.4877e-01, -4.0843e-02,  7.5679e-03],\n",
       "                        [-1.6919e-01, -3.1479e-02, -6.7946e-02, -3.4137e-02,  7.4583e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6911e-01, -1.6166e-01,  2.3316e-01,  1.3514e-01, -2.9528e-01],\n",
       "                        [-4.5961e-01, -4.3139e-02,  5.4142e-01, -2.7920e-01, -3.5257e-02],\n",
       "                        [ 2.6260e-01,  3.4767e-01, -2.0819e-01, -5.9274e-01,  2.2303e-01],\n",
       "                        [ 4.5426e-02, -1.0069e-01,  1.4518e-01, -2.4906e-01,  8.3269e-02],\n",
       "                        [-1.7459e-01, -5.1138e-01,  1.4200e-01,  2.3060e-01, -1.7630e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.5347e-01,  1.7400e-01, -1.6627e-01, -2.3845e-01, -7.4360e-02],\n",
       "                        [ 1.6225e-01, -1.3896e-01,  3.4234e-01,  3.5261e-01,  1.6900e-01],\n",
       "                        [-9.1116e-02, -8.5872e-02,  1.9658e-01,  3.4722e-01,  3.8472e-01],\n",
       "                        [-2.3127e-01, -3.0856e-01, -2.0759e-01, -1.8422e-01,  1.1139e-01],\n",
       "                        [-1.1157e-01, -3.7495e-01, -5.2093e-01, -6.6021e-01, -3.4236e-01]]]])),\n",
       "             ('conv1.0.bias',\n",
       "              tensor([-0.1582, -0.3100,  0.1637, -0.2226, -0.5646, -0.2664, -0.1388, -0.0288,\n",
       "                      -0.2516, -0.1174, -0.2416, -0.2493, -0.0859,  0.0381, -0.0306, -0.0480])),\n",
       "             ('conv2.0.weight',\n",
       "              tensor([[[[-8.0756e-02,  1.1656e-01,  9.4000e-03, -1.7096e-01, -1.0092e-01],\n",
       "                        [ 6.8871e-02,  2.3491e-01, -4.2986e-02, -1.1238e-01, -8.1760e-02],\n",
       "                        [ 1.9722e-01,  3.1024e-01, -2.4955e-01, -1.5462e-01, -1.5901e-01],\n",
       "                        [ 1.0427e-01, -3.9510e-03,  7.8964e-02,  9.9491e-02,  1.9042e-01],\n",
       "                        [-2.8523e-01,  1.0494e-01,  2.3572e-01,  1.4105e-01,  1.3746e-01]],\n",
       "              \n",
       "                       [[ 2.9213e-02,  1.0142e-01, -5.3059e-02,  6.7832e-02,  2.8225e-01],\n",
       "                        [-4.1130e-02,  1.9426e-01,  5.3045e-02,  6.9289e-02,  2.8912e-01],\n",
       "                        [ 1.5477e-01, -5.7925e-02, -2.9936e-01, -4.5689e-01, -2.3938e-01],\n",
       "                        [-6.1827e-02, -2.2973e-01, -3.2704e-01, -2.8947e-01, -1.3033e-01],\n",
       "                        [-3.5241e-01,  6.4540e-02, -1.6107e-01, -3.0001e-02,  1.4086e-01]],\n",
       "              \n",
       "                       [[ 8.0693e-02,  9.1545e-02, -9.1974e-03, -4.1254e-03,  2.1840e-01],\n",
       "                        [ 2.2916e-02, -1.3256e-01, -2.5690e-01, -1.3408e-01,  1.6060e-02],\n",
       "                        [ 1.1386e-01,  9.7636e-02,  6.3847e-03, -4.7540e-01, -5.8166e-01],\n",
       "                        [-2.1256e-02, -2.1951e-01, -1.1179e-01, -1.3838e-01, -3.6559e-01],\n",
       "                        [-6.1238e-02, -2.9884e-02, -1.4471e-01, -7.2502e-02, -5.5091e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.5934e-01, -3.4258e-01, -1.2706e-01, -7.7576e-02, -3.0651e-01],\n",
       "                        [-2.2471e-01, -2.3568e-01, -1.9083e-02, -6.1205e-02, -4.9491e-02],\n",
       "                        [-1.6090e-01, -3.3227e-01, -6.0073e-02,  7.0817e-02,  9.5231e-02],\n",
       "                        [ 3.8117e-02,  1.1544e-01, -8.1547e-03, -1.0128e-01, -2.5411e-01],\n",
       "                        [ 2.6246e-01,  2.8422e-01,  1.2551e-01, -5.0770e-01, -1.5693e-01]],\n",
       "              \n",
       "                       [[-6.2363e-02,  4.3444e-02,  7.1217e-02,  3.7686e-01,  2.9525e-01],\n",
       "                        [ 2.3407e-01,  1.1063e-01,  1.5369e-01,  5.8721e-02, -9.1101e-02],\n",
       "                        [-9.4089e-02, -4.9600e-02, -6.9270e-01, -4.0657e-01, -3.8784e-02],\n",
       "                        [-3.2201e-01, -4.8655e-02, -7.4765e-02, -1.9917e-01,  5.4421e-02],\n",
       "                        [-9.2605e-02,  2.6697e-01,  1.0137e-01,  1.6796e-01,  4.1711e-01]],\n",
       "              \n",
       "                       [[-2.6171e-01, -1.0050e-01,  1.5599e-01, -1.5165e-01, -5.2304e-01],\n",
       "                        [-2.1379e-01, -7.3422e-02,  9.9348e-02,  9.1658e-02,  4.4853e-02],\n",
       "                        [-2.2046e-01,  5.1539e-03, -5.6654e-02, -3.7910e-02, -5.0634e-02],\n",
       "                        [ 8.4650e-02,  7.3104e-02, -2.0434e-01, -2.3159e-01, -2.3546e-01],\n",
       "                        [ 1.3714e-01, -1.0570e-01,  6.8822e-02,  3.2025e-01,  1.1619e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6996e-03, -3.3377e-02,  1.6711e-01, -5.4287e-02, -3.7888e-02],\n",
       "                        [-1.8229e-01,  8.7827e-02,  2.8392e-01,  1.7169e-01,  1.3703e-01],\n",
       "                        [-2.7570e-01,  6.4937e-02,  2.6141e-01,  3.2710e-01,  1.4962e-01],\n",
       "                        [-6.4432e-01, -1.9922e-01, -1.5608e-01, -2.2320e-01, -2.0665e-01],\n",
       "                        [-1.8144e-01, -6.8052e-02,  1.6708e-01,  7.8637e-02,  1.6702e-01]],\n",
       "              \n",
       "                       [[-2.8883e-01,  6.0817e-02,  4.8371e-02,  2.6204e-01, -1.0751e-01],\n",
       "                        [ 1.9271e-01,  1.0449e-02, -7.7014e-03,  1.8401e-01,  2.7334e-02],\n",
       "                        [ 1.8486e-01, -2.2853e-01,  2.7449e-01, -1.9384e-01, -3.3244e-01],\n",
       "                        [ 7.6199e-02, -4.1464e-02, -2.3594e-01,  2.8133e-02, -2.3827e-02],\n",
       "                        [-4.8031e-03, -7.6039e-02,  2.5027e-01,  4.5033e-02,  5.3633e-02]],\n",
       "              \n",
       "                       [[-1.3713e-01, -1.0463e-01,  6.7558e-02,  2.7202e-02,  1.2963e-02],\n",
       "                        [ 1.2093e-02, -1.8595e-02, -4.0119e-02, -8.4045e-03,  2.2915e-02],\n",
       "                        [ 9.0724e-02,  7.8355e-02, -1.2481e-01, -7.6906e-02, -5.6974e-02],\n",
       "                        [-3.1823e-01, -4.2775e-01, -3.6523e-01, -4.7794e-01, -3.4026e-01],\n",
       "                        [ 2.7306e-01,  3.1257e-01,  1.4259e-01,  1.0272e-01,  8.3731e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.1544e-01, -1.7381e-01,  3.5810e-02,  9.1962e-02,  7.1929e-03],\n",
       "                        [ 3.9245e-02, -1.1935e-01, -3.0134e-01, -3.2839e-01, -2.3195e-01],\n",
       "                        [ 7.3399e-02, -1.6263e-01, -2.1301e-01, -6.6153e-02, -4.5181e-02],\n",
       "                        [ 3.1874e-01,  4.4623e-01,  4.1107e-01,  1.9629e-01, -8.4182e-02],\n",
       "                        [-2.2789e-01, -4.2250e-02, -4.4307e-02, -1.4177e-01, -5.8961e-01]],\n",
       "              \n",
       "                       [[ 2.0282e-01,  9.4401e-02, -6.4904e-03, -1.3196e-01, -1.9577e-01],\n",
       "                        [ 1.5976e-01,  2.7860e-01,  2.0126e-01, -6.0544e-02, -4.1622e-01],\n",
       "                        [ 1.8468e-01,  2.8347e-01,  1.6760e-01, -2.7677e-02, -6.0140e-02],\n",
       "                        [-3.9938e-01, -6.9739e-02,  1.0641e-01, -9.9799e-02, -6.2955e-02],\n",
       "                        [-3.3221e-01, -2.9445e-01, -6.3166e-02, -1.7303e-01, -1.5341e-01]],\n",
       "              \n",
       "                       [[-3.4778e-01, -8.6833e-03, -8.4513e-02, -1.5144e-01, -9.4930e-02],\n",
       "                        [-4.0823e-01, -3.1932e-01, -1.9705e-01, -1.0893e-01,  9.2318e-03],\n",
       "                        [ 7.1660e-02,  7.4511e-02, -8.7057e-02, -6.1389e-02, -1.5007e-01],\n",
       "                        [ 2.8984e-01,  4.2472e-01,  2.3724e-01, -1.5885e-01, -5.1957e-01],\n",
       "                        [-3.7940e-01, -5.7110e-01, -5.5168e-01, -3.6155e-01, -6.5152e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.1934e-02,  1.9669e-01,  6.7095e-02, -6.9312e-01, -2.3870e-01],\n",
       "                        [ 1.5931e-01,  2.6946e-01, -3.6203e-01, -5.2307e-01, -3.9389e-02],\n",
       "                        [ 2.7132e-01,  1.5227e-01, -8.3747e-01,  1.1959e-01,  2.3035e-01],\n",
       "                        [ 2.9209e-01,  1.0444e-01, -6.6857e-01,  2.6235e-01,  4.3435e-02],\n",
       "                        [ 3.4524e-01,  5.0531e-03, -6.2065e-02,  1.4413e-01,  2.5387e-02]],\n",
       "              \n",
       "                       [[-2.6616e-01, -2.1621e-01, -2.4269e-01, -2.1850e-01, -1.2310e-01],\n",
       "                        [-1.2216e-01, -9.1217e-02, -1.8145e-01, -3.1866e-01, -5.9426e-02],\n",
       "                        [-9.5225e-02, -8.3012e-02, -3.6233e-01, -6.0575e-02, -6.7624e-02],\n",
       "                        [-1.4688e-01, -1.3312e-01,  4.2173e-02, -8.1814e-02, -8.0351e-02],\n",
       "                        [-3.4489e-01, -1.0185e-02,  1.5351e-01, -1.2700e-01,  1.9633e-01]],\n",
       "              \n",
       "                       [[-1.1873e-01, -4.6849e-02, -2.1150e-01, -2.4941e-01, -2.9839e-02],\n",
       "                        [ 1.1667e-01, -2.3524e-02, -8.0107e-02, -5.5915e-03,  1.6983e-01],\n",
       "                        [ 7.6823e-02,  2.5437e-02,  5.4723e-02,  9.3716e-02,  1.1116e-01],\n",
       "                        [ 1.4514e-02,  3.9352e-02, -1.1649e-01, -6.3207e-02, -4.2619e-02],\n",
       "                        [ 6.1757e-02, -1.8250e-01, -2.1889e-01, -1.1194e-01, -8.2201e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.7503e-01, -1.3732e-02, -4.7270e-01, -3.9376e-02,  1.0496e-01],\n",
       "                        [-6.6338e-02, -3.0338e-01, -8.8321e-01, -2.1545e-01,  1.0259e-02],\n",
       "                        [-6.6417e-02, -2.0477e-01, -2.6213e-01, -2.8529e-01, -2.3524e-02],\n",
       "                        [-7.5053e-03, -1.0121e-01, -1.6268e-01, -3.3721e-01, -2.3614e-01],\n",
       "                        [-6.1304e-02, -1.4408e-01, -3.0767e-01, -4.9679e-01, -5.1521e-01]],\n",
       "              \n",
       "                       [[-5.4217e-02,  1.0052e-01, -1.0696e-01, -1.7948e-01,  1.0702e-01],\n",
       "                        [ 3.2244e-01,  4.7140e-02, -1.0526e-01, -1.1507e-01, -1.3811e-01],\n",
       "                        [-9.9970e-02,  1.5215e-02,  1.0728e-02, -3.1744e-01,  1.2832e-01],\n",
       "                        [ 4.3919e-03,  4.1181e-02, -2.6895e-02, -2.3486e-01, -6.0422e-02],\n",
       "                        [ 9.5811e-02,  2.2733e-01,  1.0393e-01, -2.9273e-01,  1.5807e-01]],\n",
       "              \n",
       "                       [[-2.1342e-01, -2.3664e-01, -4.4603e-01, -1.0896e-01, -2.1513e-01],\n",
       "                        [-3.2365e-01, -1.4517e-01, -3.6794e-01, -1.3314e-01, -2.6099e-01],\n",
       "                        [-2.7631e-02, -3.2700e-02, -3.0110e-01, -1.1315e-01, -2.7422e-01],\n",
       "                        [-6.6362e-02, -2.7502e-01, -1.2385e-01, -2.3834e-01, -4.8593e-01],\n",
       "                        [ 9.0520e-02, -1.8605e-01, -4.1036e-01, -4.7628e-01, -3.7929e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 3.5765e-02, -7.8233e-02, -2.8872e-02,  1.0378e-02,  2.3551e-02],\n",
       "                        [-9.4438e-02, -2.3674e-01,  2.8614e-02,  4.2978e-02, -1.4044e-01],\n",
       "                        [-2.6940e-01, -1.2795e-01,  2.6036e-02, -4.8394e-02, -4.5134e-02],\n",
       "                        [-1.4304e-01,  5.5459e-03, -7.3505e-03,  4.3100e-03, -5.8495e-02],\n",
       "                        [ 7.1824e-02, -1.6709e-03,  1.3187e-01, -1.2215e-01, -7.4200e-01]],\n",
       "              \n",
       "                       [[-3.0836e-02,  2.1556e-01, -2.5512e-01, -3.4729e-02,  3.3517e-01],\n",
       "                        [-2.1180e-01, -7.9373e-02, -1.5583e-01, -5.7232e-02, -9.9857e-02],\n",
       "                        [-2.3730e-01, -4.8695e-01, -3.7118e-01, -2.6226e-01,  7.2945e-03],\n",
       "                        [-2.5921e-01, -3.3923e-01,  1.2507e-01,  1.4604e-01,  2.6761e-02],\n",
       "                        [-9.0295e-02, -1.3248e-01,  1.6210e-01,  2.0984e-01, -1.5064e-01]],\n",
       "              \n",
       "                       [[ 4.4662e-02, -1.0761e-01, -9.1367e-02, -1.0204e-01, -1.4334e-01],\n",
       "                        [ 6.9518e-02, -2.5209e-01, -1.3238e-01, -1.9633e-01, -5.5379e-02],\n",
       "                        [-5.7446e-02, -3.5097e-01, -2.3897e-01, -5.4471e-01, -2.9833e-01],\n",
       "                        [-1.6363e-02, -1.9771e-01, -2.9968e-01, -3.0060e-01, -1.0099e-01],\n",
       "                        [ 4.0924e-02,  1.2294e-02, -9.2800e-02, -3.4696e-01, -6.2908e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.9937e-02,  1.3350e-01,  2.9051e-01, -2.5181e-01, -3.8012e-01],\n",
       "                        [ 1.0119e-01,  1.1533e-01,  2.1092e-01, -2.7900e-01, -2.4720e-01],\n",
       "                        [ 1.7614e-01,  9.8788e-02,  1.1713e-01, -2.0065e-01, -1.8089e-01],\n",
       "                        [ 8.2398e-02,  9.4972e-02,  4.1826e-02,  2.3070e-02, -2.5667e-01],\n",
       "                        [ 9.8738e-02,  3.7065e-02, -3.7317e-02,  6.8759e-02,  1.1805e-01]],\n",
       "              \n",
       "                       [[-2.6397e-01, -5.6665e-01,  8.3527e-02,  1.2547e-01, -4.8876e-01],\n",
       "                        [-3.1453e-01, -5.7482e-02, -9.7770e-02,  7.3357e-03, -3.4074e-01],\n",
       "                        [-4.4149e-01, -3.1263e-01,  6.5392e-02, -1.2037e-01, -2.8029e-01],\n",
       "                        [-2.4759e-01, -3.9738e-01, -5.6350e-02,  1.0736e-01, -2.6822e-01],\n",
       "                        [ 6.1982e-02, -3.2809e-01, -3.8781e-01, -1.5693e-01,  6.4034e-02]],\n",
       "              \n",
       "                       [[ 1.8541e-01,  8.1095e-02, -1.2002e-01, -2.6607e-01,  1.0198e-01],\n",
       "                        [ 1.2066e-01, -5.7978e-02, -9.4145e-02, -2.6888e-01,  2.2377e-01],\n",
       "                        [ 8.3427e-03, -2.0230e-01, -2.6678e-03, -1.0647e-02,  9.6488e-02],\n",
       "                        [ 2.0693e-01,  1.1650e-01,  1.3779e-01,  5.0509e-02,  5.1971e-02],\n",
       "                        [ 2.0678e-01, -1.7191e-02,  1.2555e-01,  1.6403e-01,  8.6226e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4264e-01,  2.7611e-02,  3.1306e-02, -9.0366e-02, -3.3360e-01],\n",
       "                        [-1.5754e-01,  1.2256e-01,  1.7088e-01, -7.2540e-02, -6.5626e-01],\n",
       "                        [-5.3705e-02,  1.4116e-01,  1.6224e-01, -3.4621e-01,  5.6970e-03],\n",
       "                        [ 7.0680e-02, -3.0799e-01, -2.0522e-01, -4.5104e-02, -1.2638e-01],\n",
       "                        [-3.1201e-01, -2.0876e-01,  1.8401e-02, -1.6545e-01,  6.1389e-02]],\n",
       "              \n",
       "                       [[ 1.9035e-01, -5.6378e-03, -2.1573e-01, -4.7314e-01, -2.6214e-01],\n",
       "                        [ 8.8876e-04, -7.0251e-02, -4.9201e-02, -2.2662e-01, -3.1803e-01],\n",
       "                        [ 3.0805e-01,  1.4264e-01, -3.8767e-01,  4.8406e-02,  2.1903e-01],\n",
       "                        [-2.7274e-01, -9.6403e-02,  3.2793e-01,  3.0393e-01,  1.3289e-01],\n",
       "                        [-3.0618e-01,  3.3112e-01,  3.4320e-01,  1.9289e-01, -1.1859e-02]],\n",
       "              \n",
       "                       [[ 2.9129e-01,  1.9904e-01,  1.6810e-01, -9.8971e-02, -3.1792e-01],\n",
       "                        [ 1.0924e-01,  9.5671e-02, -7.9529e-02, -1.6811e-01, -2.0312e-01],\n",
       "                        [ 2.2900e-01,  9.3487e-02, -3.3516e-01, -7.4472e-01, -3.1989e-01],\n",
       "                        [ 4.6616e-02, -5.9376e-01, -6.9783e-01, -9.9748e-02,  1.1762e-01],\n",
       "                        [-5.2092e-01, -7.5069e-01, -1.8630e-01,  2.3158e-01,  2.4431e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.2331e-02,  1.7839e-01,  2.0026e-01, -1.3569e-01,  8.1137e-03],\n",
       "                        [ 2.4832e-02,  2.1187e-01, -3.0323e-01, -8.1865e-02, -1.2390e-01],\n",
       "                        [ 7.8635e-02, -4.0471e-01, -2.8559e-01,  1.0163e-01,  1.1153e-02],\n",
       "                        [-9.0341e-03, -8.6918e-02,  1.1830e-02, -3.7511e-02, -1.1699e-01],\n",
       "                        [ 1.4948e-01,  6.1815e-02, -1.9618e-01, -2.2268e-01, -3.2184e-01]],\n",
       "              \n",
       "                       [[-2.1789e-01, -1.0038e-01, -5.6074e-02, -1.9997e-02, -3.3836e-01],\n",
       "                        [-4.9906e-02,  3.5236e-01,  3.8368e-01,  1.2642e-01, -2.5663e-01],\n",
       "                        [-2.7768e-02, -8.2050e-02,  4.6230e-01,  2.1642e-01, -1.6891e-01],\n",
       "                        [ 1.4689e-01,  3.5161e-01, -1.4528e-01,  3.0164e-01,  3.2329e-01],\n",
       "                        [ 2.0580e-01,  2.3124e-02, -1.5434e-01,  1.0178e-01, -1.6513e-01]],\n",
       "              \n",
       "                       [[ 6.6825e-03, -3.5096e-02,  3.8517e-02, -1.9201e-01,  4.9439e-02],\n",
       "                        [ 5.8012e-02, -4.7118e-02,  3.9715e-03, -1.2427e-01, -2.1549e-01],\n",
       "                        [-1.4374e-01,  4.1595e-03,  3.3700e-02,  1.4767e-01, -1.5919e-01],\n",
       "                        [-9.5655e-02,  3.8757e-02, -8.4182e-02, -3.7852e-02, -1.2746e-01],\n",
       "                        [ 2.9578e-02,  2.0507e-01,  3.1234e-02, -3.5023e-01, -2.3714e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.5201e-01,  7.7592e-02, -9.0173e-02, -5.9064e-02,  2.0188e-01],\n",
       "                        [-6.8098e-02, -2.0934e-02,  2.1278e-02,  2.7674e-01,  2.4286e-01],\n",
       "                        [ 2.9427e-02,  1.4737e-01,  1.0864e-01, -5.3428e-02, -2.5646e-02],\n",
       "                        [ 1.1365e-01, -1.8488e-01, -5.6078e-01, -2.3003e-01, -1.6553e-01],\n",
       "                        [-1.6933e-01, -3.9306e-01,  3.9308e-02,  2.7174e-01, -1.4362e-01]],\n",
       "              \n",
       "                       [[-3.2098e-01, -3.7698e-01, -1.1063e-01, -6.2984e-02,  3.7060e-01],\n",
       "                        [-5.4271e-01, -1.2828e-01,  1.7047e-01,  3.3451e-01,  4.9900e-02],\n",
       "                        [ 7.8996e-02,  2.9090e-01,  1.8893e-01, -2.0717e-02, -1.5021e-01],\n",
       "                        [-1.6342e-01, -6.0355e-01, -5.0759e-01, -1.5635e-01, -1.3574e-01],\n",
       "                        [ 2.6138e-01,  1.3231e-01, -1.7925e-01, -1.3678e-01, -2.5140e-01]],\n",
       "              \n",
       "                       [[-1.6703e-01, -2.9342e-01, -2.5155e-01, -1.7897e-01, -1.5442e-01],\n",
       "                        [-2.4389e-01, -1.5573e-01, -1.0621e-01,  6.2779e-02,  6.9447e-03],\n",
       "                        [-1.5295e-01, -1.8965e-01, -1.8873e-01, -9.5644e-02, -1.4866e-01],\n",
       "                        [ 1.3124e-01, -2.1769e-01, -3.7629e-01, -2.7759e-01, -3.1036e-01],\n",
       "                        [-6.5074e-02, -1.7623e-01, -1.7064e-01, -2.5592e-01, -5.9753e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 9.9811e-02, -2.5033e-01, -2.3376e-01, -1.0563e-01, -2.3604e-01],\n",
       "                        [-3.4109e-01, -1.6677e-01, -1.5765e-01, -5.6703e-01, -9.2089e-01],\n",
       "                        [-1.6390e-01, -3.5859e-01, -7.3612e-02, -5.6292e-03, -8.2021e-02],\n",
       "                        [ 3.7136e-04, -3.3436e-02,  1.3455e-01,  2.0132e-01, -1.1443e-01],\n",
       "                        [ 4.4129e-01,  4.3217e-01,  1.9081e-01, -3.2074e-01, -2.9613e-01]],\n",
       "              \n",
       "                       [[ 1.5559e-03, -2.4355e-02, -4.5246e-02,  2.4162e-01,  1.5332e-01],\n",
       "                        [-8.7273e-02,  2.9784e-01,  4.9390e-02,  5.0214e-02,  1.5320e-01],\n",
       "                        [ 1.2756e-01, -1.1541e-01,  2.2031e-02,  7.1418e-02,  1.3019e-01],\n",
       "                        [ 2.5146e-01,  9.0729e-02,  2.1846e-01,  1.8138e-01, -1.6863e-01],\n",
       "                        [-2.8787e-01,  3.3969e-02, -1.2078e-01, -9.8605e-02,  2.3737e-01]],\n",
       "              \n",
       "                       [[-1.7250e-01, -2.2162e-01, -2.2445e-01, -1.8748e-01, -3.9155e-01],\n",
       "                        [-1.3615e-01, -2.1391e-01, -1.7151e-01, -3.8576e-01, -4.8148e-01],\n",
       "                        [-1.4998e-01, -4.8196e-03,  4.1556e-02, -3.6323e-02, -4.5252e-01],\n",
       "                        [ 3.0868e-01, -1.4362e-02, -1.1644e-01, -1.3153e-01, -1.3524e-01],\n",
       "                        [ 3.2440e-01, -7.2185e-02, -3.0679e-01, -1.9618e-01, -2.0950e-01]]]])),\n",
       "             ('conv2.0.bias',\n",
       "              tensor([-0.2621, -0.1983, -0.0477, -0.0143, -0.3051, -0.2498, -0.1346, -0.0680,\n",
       "                      -0.0920, -0.2139, -0.1278, -0.0979, -0.2196, -0.0151,  0.0239, -0.1367,\n",
       "                      -0.0786, -0.1533, -0.0782, -0.0479, -0.2164, -0.2090, -0.1843, -0.2840,\n",
       "                      -0.1566, -0.2403, -0.1441,  0.0101, -0.0731, -0.0735, -0.1488, -0.0559])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[ 0.0115,  0.0649,  0.0382,  ..., -0.1633, -0.0774,  0.0012],\n",
       "                      [-0.0850,  0.0146, -0.0074,  ..., -0.3274, -0.1589, -0.0206],\n",
       "                      [ 0.0480,  0.1320,  0.0657,  ..., -0.1623, -0.0744, -0.0423],\n",
       "                      ...,\n",
       "                      [-0.0273, -0.0516, -0.1192,  ...,  0.0774,  0.2034, -0.0112],\n",
       "                      [-0.1059, -0.0620, -0.0805,  ..., -0.4901, -0.1071, -0.1196],\n",
       "                      [ 0.0234,  0.0594,  0.0573,  ...,  0.0542, -0.1061,  0.1880]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 0.0506,  0.1536, -0.0496,  0.0260, -0.0819, -0.0012, -0.0695, -0.0365,\n",
       "                       0.0709, -0.0801]))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Essentially what is being saved is the the set of weights a model uses between neurons\n",
    "model.state_dict()\n",
    "\n",
    "# Next time we will reload them into a new model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
