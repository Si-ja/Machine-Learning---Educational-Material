{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Optimizations\n",
    "\n",
    "- Created by: Si_ja\n",
    "- https://github.com/Si-ja\n",
    "- Date: 2019-05-02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is something I wanted to experiment with and make a valuable note for quite some time. During one of my lectures for data processing with python, a lecturer made one valuable note - as a beginner your code most likely will not be optimized and will run sometimes slow...much slow than that of professionals...and that is ok. To learn how to optimize it - start small and think about little things that you can improve while making it, not afterwards.\n",
    "\n",
    "One of such examples were defining a value, so that it would not have to be re-calculated multiple times. As though with small amounts of data it might bring a noticable difference, but with enormous amounts - it might matter. This of course more heavily applies towards functions. Let's take a small example that is not too close to the real world, but can deliver a point.\n",
    "\n",
    "For the sake of being able to time everything we will import packages we need before hand and not only from the functions, how it should be. For time there are also more optimal solutions how to track it, but we will use a very simple example, as this small guide is ment only for ideas stimulation for beginners rather than professionals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.42009127 -0.83753575 -2.81644231 -4.58927255 -4.91579916 -2.2887476\n",
      "  2.25760517 -3.86117443  0.04647647 -3.65476449]\n"
     ]
    }
   ],
   "source": [
    "#a value z will just be our holder of information, having 10 \"random\" values generated for it.\n",
    "#We will later increase it, so far it's only an example.\n",
    "z = np.random.normal(0,2,10)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I don't want to get too much into the idea behind softmax function, if you are interested, please read:\n",
    "#https://en.wikipedia.org/wiki/Softmax_function\n",
    "#But my advice for now - just take it as it. For us it only matters how it is written.\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that our function is very conveniently made into one line of code. But there is a small issue. Have you noticed that np.exp(x) is calculated twice? That is something that might affect the processing time in the future. Now let us see an example when we mitigate that issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_opt(x):\n",
    "    E = np.exp(x)\n",
    "    return E /np.sum(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above actually does not require a double recalculation of the exp(x), as it is only done one and stored into a variable. Now for one - this should be a faster method, but of course, when you are chosing which to use - it comes with a price of evaluating what resources you can utilize best - the memory or time.\n",
    "\n",
    "However, let us finally see an example how much time the functions take to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For softmax function it took 0.0 seconds to run.\n",
      "-----------------------------------------------------------------\n",
      "For softmax_opt function it took 0.0 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "softmax(z)\n",
    "t1 = time()\n",
    "print(\"For softmax function it took {} seconds to run.\".format(np.round(t1-t0, 4)))\n",
    "print(\"-----------------------------------------------------------------\")\n",
    "\n",
    "t0 = time()\n",
    "softmax_opt(z)\n",
    "t1 = time()\n",
    "print(\"For softmax_opt function it took {} seconds to run.\".format(np.round(t1-t0, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well...not difference...was I wrong? Let's try something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "z = np.random.normal(0,2,10000)\n",
    "print(len(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For softmax function it took 0.3194 seconds to run.\n",
      "-----------------------------------------------------------------\n",
      "For softmax_opt function it took 0.0 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "softmax(z)\n",
    "t1 = time()\n",
    "print(\"For softmax function it took {} seconds to run.\".format(np.round(t1-t0, 4)))\n",
    "print(\"-----------------------------------------------------------------\")\n",
    "\n",
    "t0 = time()\n",
    "softmax_opt(z)\n",
    "t1 = time()\n",
    "print(\"For softmax_opt function it took {} seconds to run.\".format(np.round(t1-t0, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still almost nothing...uh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "z = np.random.normal(0,2,1000000)\n",
    "print(len(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For softmax function it took 0.0299 seconds to run.\n",
      "-----------------------------------------------------------------\n",
      "For softmax_opt function it took 0.0189 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "softmax(z)\n",
    "t1 = time()\n",
    "print(\"For softmax function it took {} seconds to run.\".format(np.round(t1-t0, 4)))\n",
    "print(\"-----------------------------------------------------------------\")\n",
    "\n",
    "t0 = time()\n",
    "softmax_opt(z)\n",
    "t1 = time()\n",
    "print(\"For softmax_opt function it took {} seconds to run.\".format(np.round(t1-t0, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah! There we go, something is chaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000000\n"
     ]
    }
   ],
   "source": [
    "z = np.random.normal(0,2,100000000)\n",
    "print(len(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For softmax function it took 1.7177 seconds to run.\n",
      "-----------------------------------------------------------------\n",
      "For softmax_opt function it took 1.363 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "softmax(z)\n",
    "t1 = time()\n",
    "print(\"For softmax function it took {} seconds to run.\".format(np.round(t1-t0, 4)))\n",
    "print(\"-----------------------------------------------------------------\")\n",
    "\n",
    "t0 = time()\n",
    "softmax_opt(z)\n",
    "t1 = time()\n",
    "print(\"For softmax_opt function it took {} seconds to run.\".format(np.round(t1-t0, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go. Not a insane improvement, but do notice that improvement of ~$1$ second, for large amounts of data is quite something, considering the only thing that was done - is taking away of one calculation procedure that was repeating. Considering also that the calculation was saved in the variable inside of the function, long term - it should not affect the memory storage too much, as it will stop existing as soon as the function finishes (for the given case).\n",
    "\n",
    "This is only a small example of how such improvements can help, but imagine you are running a huge function with many smaller functions that just simply process the data and return a small report on it. 1 additional second per each calculation in the long term can matter.\n",
    "\n",
    "Naturally, this is just an educational example and is ment to give an idea about optimizations. There is much more that can be done about this, but it's good to start small with such things."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
